{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa29b053",
   "metadata": {},
   "source": [
    "<h1> Data Utils </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081dda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wget\n",
    "import zipfile\n",
    "import json5  \n",
    "from safetensors.torch import load_file, save_file \n",
    "from typing import Tuple, List, Dict\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import random\n",
    "\n",
    "from config_setup import TrainingConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6882ac",
   "metadata": {},
   "source": [
    "<h3> Download and Prepare Data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_prepare_data(config: TrainingConfig) -> List[str]:\n",
    "\n",
    "    \"\"\"\n",
    "    It checks, downloads and extracts the data. Then, it builds and returns\n",
    "    the list of .mat files to use for training.\n",
    "    \"\"\"\n",
    "    zip_path = os.path.join(config.base_data_dir, f\"{config.dataset_name}.zip\")\n",
    "    \n",
    "    example_mat_file = os.path.join(config.dataset_path, f\"{config.dataset_name}a_A.mat\")\n",
    "    if not os.path.exists(example_mat_file):\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(f\"Downloading data from {config.raw_data_zip_url}...\")\n",
    "            wget.download(config.raw_data_zip_url, zip_path)\n",
    "            print(\"Download complete.\")\n",
    "        \n",
    "        print(f\"Extracting data to {config.dataset_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(config.dataset_path)\n",
    "        print(\"Extraction complete.\")\n",
    "    else:\n",
    "        print(f\"Data already found in {config.dataset_path}\")\n",
    "\n",
    "    file_list = []\n",
    "    receivers = config.receivers if isinstance(config.receivers, list) else [config.receivers]\n",
    "    activities = config.activities if isinstance(config.activities, list) else [config.activities]\n",
    "\n",
    "    print(f\"Building file list for scenario {config.dataset_name}...\")\n",
    "    print(f\"Receivers: {receivers}, Activities: {activities}\")\n",
    "\n",
    "    for receiver_id in receivers:\n",
    "        for activity_id in activities:\n",
    "            file_name = f\"{config.dataset_name}{receiver_id}_{activity_id}.mat\"\n",
    "            full_path = os.path.join(config.dataset_path, file_name)\n",
    "            \n",
    "            if os.path.exists(full_path):\n",
    "                file_list.append(full_path)\n",
    "            else:\n",
    "                print(f\"Warning: File not found and will be skipped: {full_path}\")\n",
    "    \n",
    "    if not file_list:\n",
    "        raise FileNotFoundError(\"ERROR: No files found for the specified configuration.\")\n",
    "        \n",
    "    print(f\"Generated file list for the dataset ({len(file_list)} files): {file_list}\")\n",
    "    \n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8fff0",
   "metadata": {},
   "source": [
    "<h3> Prepare CSI Dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9217d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsiPyTorchDataset(Dataset):\n",
    "    def __init__(self, config: TrainingConfig, file_list: List[str]):\n",
    "        self.config = config\n",
    "        self.window_size = config.window_size\n",
    "        self.samples_per_file = config.samples_per_file\n",
    "        self.antenna_indices = config.antenna_indices\n",
    "        self.input_channels = config.input_channels\n",
    "\n",
    "        self.all_csi_segments = []\n",
    "        self.all_labels_for_windows = []\n",
    "        self.all_start_indices_in_concatenated_csi = []\n",
    "\n",
    "        current_concat_offset = 0\n",
    "        print(\"Loading MAT files...\")\n",
    "        for activity_idx, file_path in enumerate(file_list):\n",
    "            try:\n",
    "                mat = sio.loadmat(file_path)\n",
    "                data = np.array(mat['csi'])  # Shape (raw_samples, features, num_antennas_in_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}. Skipped.\")\n",
    "                continue\n",
    "\n",
    "            num_raw_samples_in_file = data.shape[0]\n",
    "            samples_to_take = min(self.samples_per_file, num_raw_samples_in_file)\n",
    "            \n",
    "            # --- Antenna selection logic ---\n",
    "            max_antenna_idx = max(self.antenna_indices)\n",
    "            if data.ndim < 3 or data.shape[2] <= max_antenna_idx:\n",
    "                raise ValueError(f\"Data in {file_path} is not compatible. Required antenna index {max_antenna_idx}, \"\n",
    "                                 f\"but data shape is {data.shape}.\")\n",
    "\n",
    "            # Select the specified antennas and maintain the shape for subsequent processing\n",
    "            selected_data = data[:samples_to_take, :, self.antenna_indices]\n",
    "            \n",
    "            # If only one antenna is selected, np.squeeze might remove the dimension. We restore it.\n",
    "            if selected_data.ndim == 2:\n",
    "                selected_data = np.expand_dims(selected_data, axis=2)\n",
    "\n",
    "            data = np.round(np.abs(selected_data)).astype(np.float32)\n",
    "            self.all_csi_segments.append(torch.from_numpy(data))\n",
    "\n",
    "            num_possible_windows_this_file = data.shape[0] - self.window_size + 1\n",
    "            if num_possible_windows_this_file <= 0:\n",
    "                print(f\"Warning: samples_per_file ({data.shape[0]}) in {file_path} is less than window_size ({self.window_size}).\")\n",
    "                continue\n",
    "            \n",
    "            for i in range(num_possible_windows_this_file):\n",
    "                self.all_start_indices_in_concatenated_csi.append(current_concat_offset + i)\n",
    "                self.all_labels_for_windows.append(activity_idx)\n",
    "\n",
    "            current_concat_offset += data.shape[0]\n",
    "            print(f\"Processed  {file_path}, {num_possible_windows_this_file} windows added.\")\n",
    "\n",
    "        if not self.all_csi_segments:\n",
    "            raise RuntimeError(\"No CSI data loaded. Check paths and MAT files.\")\n",
    "\n",
    "        self.csi_data_concatenated = torch.cat(self.all_csi_segments, dim=0)\n",
    "\n",
    "        # Normalization of CSI data\n",
    "        if self.csi_data_concatenated.numel() > 0:\n",
    "            max_val = torch.max(self.csi_data_concatenated)\n",
    "            if max_val > 0:\n",
    "                self.csi_data_concatenated /= max_val\n",
    "        \n",
    "        print(f\"Dataset initialized. CSI shape: {self.csi_data_concatenated.shape}\")\n",
    "        print(f\"Total number of windows: {len(self)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_start_indices_in_concatenated_csi)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        actual_start_idx = self.all_start_indices_in_concatenated_csi[idx]\n",
    "        window_data = self.csi_data_concatenated[actual_start_idx : actual_start_idx + self.window_size, ...]\n",
    "        \n",
    "         # PyTorch Conv2d expects (Batch, Channels, Height, Width)\n",
    "        # Here: Channels = num_antennas, Height = window_size, Width = features\n",
    "        # Permute from (window_size, features, channels) to (channels, window_size, features)\n",
    "        \n",
    "        window_data = window_data.permute(2, 0, 1)\n",
    "\n",
    "        label = self.all_labels_for_windows[idx]\n",
    "        return window_data, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a10120",
   "metadata": {},
   "source": [
    "<h3> Random Seed </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c521c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set the seed for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
