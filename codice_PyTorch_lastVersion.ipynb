{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c3e376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wget\n",
    "import zipfile\n",
    "import json5  \n",
    "from safetensors.torch import load_file, save_file \n",
    "from typing import Tuple, List, Dict, Any, Union\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539912b",
   "metadata": {},
   "source": [
    "**Configurazione**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87224d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    def __init__(self, config_path: str = 'config.json5'):\n",
    "        print(f\"Caricamento configurazione da: {config_path}\")\n",
    "        with open(config_path, 'r') as f:\n",
    "            config_data = json5.load(f)\n",
    "\n",
    "        for key, value in config_data.items():\n",
    "            setattr(self, key, value)\n",
    "        \n",
    "        self.__post_init__()\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Inizializza i campi calcolati e le directory dopo il caricamento.\"\"\"\n",
    "        if isinstance(self.antenna_indices, int):\n",
    "            self.antenna_indices = [self.antenna_indices]\n",
    "        \n",
    "        if not self.antenna_indices:\n",
    "            self.antenna_indices = list(range(4))\n",
    "            print(\"ATTENZIONE: 'antenna_indices' non specificato, si useranno tutte e 4 le antenne.\")\n",
    "\n",
    "        self.input_channels = len(self.antenna_indices)\n",
    "        \n",
    "        if self.input_channels == 1:\n",
    "            run_name_prefix = f'single_antenna_{self.antenna_indices[0]}'\n",
    "        elif self.input_channels == 4:\n",
    "            run_name_prefix = 'all_antennas'\n",
    "        else:\n",
    "            antennas_str = '_'.join(map(str, sorted(self.antenna_indices)))\n",
    "            run_name_prefix = f'custom_antennas_{antennas_str}'\n",
    "            \n",
    "        self.current_run_name = f'{run_name_prefix}'\n",
    "\n",
    "        self.current_checkpoint_dir = os.path.join(self.checkpoint_dir_base, self.current_run_name)\n",
    "        self.current_log_dir = os.path.join(self.log_dir_base, self.current_run_name)\n",
    "        self.dataset_path = os.path.join(self.base_data_dir, self.dataset_name, \"dataset\")\n",
    "\n",
    "        os.makedirs(self.current_checkpoint_dir, exist_ok=True)\n",
    "        os.makedirs(self.current_log_dir, exist_ok=True)\n",
    "        os.makedirs(self.dataset_path, exist_ok=True)\n",
    "\n",
    "        final_decoder_out_channels = self.input_channels\n",
    "        self.decoder_conv_transpose_configs.append(\n",
    "            {\"out_channels\": final_decoder_out_channels, \"kernel_size\": (1, 1), \"stride\": (1, 1), \"padding\": 0, \"activation\": \"Sigmoid\"}\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def get_activation(activation_name: str) -> nn.Module:\n",
    "        \n",
    "        if activation_name is None:\n",
    "            return nn.Identity()\n",
    "\n",
    "        try:\n",
    "            activation_class = getattr(nn, activation_name)\n",
    "            return activation_class()\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Funzione di attivazione non trovata in torch.nn: '{activation_name}'\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TrainingConfig(run_name='{self.current_run_name}', device='{self.device}')\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebd976",
   "metadata": {},
   "source": [
    "**Download e Preparazione Dati**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d89eb983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_prepare_data(config: TrainingConfig):\n",
    "    zip_path = os.path.join(config.base_data_dir, f\"{config.dataset_name}.zip\")\n",
    "    \n",
    "    example_mat_file = os.path.join(config.dataset_path, f\"{config.dataset_name}a_A.mat\")\n",
    "    if os.path.exists(example_mat_file):\n",
    "        print(f\"Dati già trovati in {config.dataset_path}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Download dati da {config.raw_data_zip_url}...\")\n",
    "        wget.download(config.raw_data_zip_url, zip_path)\n",
    "        print(\"Download completato.\")\n",
    "    else:\n",
    "        print(f\"File ZIP trovato: {zip_path}\")\n",
    "\n",
    "    print(f\"Estrazione dati in {os.path.join(config.base_data_dir, config.dataset_name)}...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(config.base_data_dir, config.dataset_name))\n",
    "    print(\"Estrazione completata.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66210d",
   "metadata": {},
   "source": [
    "**CLASSE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda85fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsiPyTorchDataset(Dataset):\n",
    "    def __init__(self, config: TrainingConfig, file_list: List[str]):\n",
    "        self.config = config\n",
    "        self.window_size = config.window_size\n",
    "        self.samples_per_file = config.samples_per_file\n",
    "        self.antenna_indices = config.antenna_indices\n",
    "        self.input_channels = config.input_channels\n",
    "\n",
    "        self.all_csi_segments = []\n",
    "        self.all_labels_for_windows = []\n",
    "        self.all_start_indices_in_concatenated_csi = []\n",
    "\n",
    "        current_concat_offset = 0\n",
    "        print(\"Caricamento file MAT...\")\n",
    "        for activity_idx, file_path in enumerate(file_list):\n",
    "            try:\n",
    "                mat = sio.loadmat(file_path)\n",
    "                data = np.array(mat['csi'])  # Shape (raw_samples, features, num_antennas_in_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Errore nel caricare {file_path}: {e}. Saltato.\")\n",
    "                continue\n",
    "\n",
    "            num_raw_samples_in_file = data.shape[0]\n",
    "            samples_to_take = min(self.samples_per_file, num_raw_samples_in_file)\n",
    "            \n",
    "            # --- Logica di selezione antenna ---\n",
    "            max_antenna_idx = max(self.antenna_indices)\n",
    "            if data.ndim < 3 or data.shape[2] <= max_antenna_idx:\n",
    "                raise ValueError(f\"Dati in {file_path} non compatibili. Richiesto indice antenna {max_antenna_idx}, \"\n",
    "                                 f\"ma la shape dei dati è {data.shape}.\")\n",
    "\n",
    "            # Seleziona le antenne specificate e mantieni la forma per la successiva elaborazione\n",
    "            selected_data = data[:samples_to_take, :, self.antenna_indices]\n",
    "            \n",
    "            # Se viene selezionata una sola antenna, np.squeeze potrebbe rimuovere la dimensione. La ripristiniamo.\n",
    "            if selected_data.ndim == 2:\n",
    "                selected_data = np.expand_dims(selected_data, axis=2)\n",
    "\n",
    "            data = np.round(np.abs(selected_data)).astype(np.float32)\n",
    "            self.all_csi_segments.append(torch.from_numpy(data))\n",
    "\n",
    "            num_possible_windows_this_file = data.shape[0] - self.window_size + 1\n",
    "            if num_possible_windows_this_file <= 0:\n",
    "                print(f\"Attenzione: samples_per_file ({data.shape[0]}) in {file_path} è minore di window_size ({self.window_size}).\")\n",
    "                continue\n",
    "            \n",
    "            for i in range(num_possible_windows_this_file):\n",
    "                self.all_start_indices_in_concatenated_csi.append(current_concat_offset + i)\n",
    "                self.all_labels_for_windows.append(activity_idx)\n",
    "\n",
    "            current_concat_offset += data.shape[0]\n",
    "            print(f\"Processato {file_path}, {num_possible_windows_this_file} finestre aggiunte.\")\n",
    "\n",
    "        if not self.all_csi_segments:\n",
    "            raise RuntimeError(\"Nessun dato CSI caricato. Controlla i percorsi e i file MAT.\")\n",
    "\n",
    "        self.csi_data_concatenated = torch.cat(self.all_csi_segments, dim=0)\n",
    "\n",
    "        # Normalizzazione\n",
    "        if self.csi_data_concatenated.numel() > 0:\n",
    "            max_val = torch.max(self.csi_data_concatenated)\n",
    "            if max_val > 0:\n",
    "                self.csi_data_concatenated /= max_val\n",
    "        \n",
    "        print(f\"Dataset inizializzato. CSI shape: {self.csi_data_concatenated.shape}\")\n",
    "        print(f\"Numero totale di finestre: {len(self)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_start_indices_in_concatenated_csi)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        actual_start_idx = self.all_start_indices_in_concatenated_csi[idx]\n",
    "        window_data = self.csi_data_concatenated[actual_start_idx : actual_start_idx + self.window_size, ...]\n",
    "        \n",
    "        # PyTorch Conv2d si aspetta (Batch, Channels, Height, Width)\n",
    "        # Qui: Channels = num_antennas, Height = window_size, Width = features\n",
    "        # Permute da (window_size, features, channels) a (channels, window_size, features)\n",
    "        window_data = window_data.permute(2, 0, 1)\n",
    "\n",
    "        label = self.all_labels_for_windows[idx]\n",
    "        return window_data, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cccc0f6",
   "metadata": {},
   "source": [
    "**ENCODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10dc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        layers = []\n",
    "        current_channels = config.input_channels\n",
    "        dummy_h, dummy_w = config.window_size, config.feature_dim \n",
    "        \n",
    "        for layer_cfg in config.encoder_conv_configs:\n",
    "            # Estrai i parametri per Conv2d, escludendo 'activation'\n",
    "            conv_params = {k: v for k, v in layer_cfg.items() if k != 'activation'}\n",
    "            layers.append(nn.Conv2d(current_channels, **conv_params))\n",
    "            current_channels = layer_cfg[\"out_channels\"]\n",
    "            if \"activation\" in layer_cfg:\n",
    "                # Chiama il metodo statico dalla classe TrainingConfig\n",
    "                layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "            \n",
    "            kh, kw = layer_cfg[\"kernel_size\"]\n",
    "            sh, sw = layer_cfg[\"stride\"]\n",
    "            ph, pw = (layer_cfg.get(\"padding\", 0),)*2 if isinstance(layer_cfg.get(\"padding\", 0), int) else layer_cfg.get(\"padding\", 0)\n",
    "            dummy_h = math.floor((dummy_h + 2 * ph - kh) / sh + 1)\n",
    "            dummy_w = math.floor((dummy_w + 2 * pw - kw) / sw + 1)\n",
    "\n",
    "        layers.append(nn.Flatten())\n",
    "        self.conv_to_flatten_shape = (current_channels, dummy_h, dummy_w)\n",
    "        flattened_size = current_channels * dummy_h * dummy_w\n",
    "        \n",
    "        current_features = flattened_size \n",
    "        for layer_cfg in config.encoder_fc_configs:\n",
    "            layers.append(nn.Linear(current_features, layer_cfg[\"out_features\"]))\n",
    "            current_features = layer_cfg[\"out_features\"]\n",
    "            if \"activation\" in layer_cfg:\n",
    "                 # Chiama il metodo statico\n",
    "                layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.fc_z_mean = nn.Linear(current_features, config.latent_dim)\n",
    "        self.fc_z_log_var = nn.Linear(current_features, config.latent_dim)\n",
    "    \n",
    "    # ... il resto della classe Encoder rimane invariato ...\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x_encoded = self.model(x)\n",
    "        z_mean = self.fc_z_mean(x_encoded)\n",
    "        z_log_var = self.fc_z_log_var(x_encoded)\n",
    "        std = torch.exp(0.5 * z_log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = z_mean + eps * std\n",
    "        return z_mean, z_log_var, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502762c",
   "metadata": {},
   "source": [
    "**DECODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b320d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config: TrainingConfig, encoder_conv_output_shape: Tuple[int, int, int]):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.encoder_conv_output_shape = encoder_conv_output_shape\n",
    "        layers = []\n",
    "        decoder_start_features = np.prod(encoder_conv_output_shape)\n",
    "        \n",
    "        current_features = config.latent_dim\n",
    "        if config.decoder_fc_configs:\n",
    "            for layer_cfg in config.decoder_fc_configs:\n",
    "                layers.append(nn.Linear(current_features, layer_cfg[\"out_features\"]))\n",
    "                current_features = layer_cfg[\"out_features\"]\n",
    "                if \"activation\" in layer_cfg:\n",
    "                    # Chiama il metodo statico\n",
    "                    layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "            layers.append(nn.Linear(current_features, decoder_start_features))\n",
    "        else:\n",
    "            layers.append(nn.Linear(config.latent_dim, decoder_start_features))\n",
    "\n",
    "        if config.encoder_fc_configs:\n",
    "             # Chiama il metodo statico\n",
    "             layers.append(TrainingConfig.get_activation(config.encoder_fc_configs[-1]['activation']))\n",
    "\n",
    "        self.fc_part = nn.Sequential(*layers)\n",
    "        \n",
    "        conv_transpose_layers = []\n",
    "        current_channels = self.encoder_conv_output_shape[0]\n",
    "        for i, layer_cfg in enumerate(config.decoder_conv_transpose_configs):\n",
    "            conv_params = {k: v for k, v in layer_cfg.items() if k != 'activation'}\n",
    "            conv_transpose_layers.append(nn.ConvTranspose2d(current_channels, **conv_params))\n",
    "            current_channels = layer_cfg[\"out_channels\"]\n",
    "            if \"activation\" in layer_cfg:\n",
    "                 # Chiama il metodo statico\n",
    "                 conv_transpose_layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "\n",
    "        self.conv_transpose_part = nn.Sequential(*conv_transpose_layers)\n",
    "        \n",
    "    # ... il resto della classe Decoder rimane invariato ...\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc_part(z)\n",
    "        x = x.view(-1, *self.encoder_conv_output_shape)\n",
    "        x_reconstructed = self.conv_transpose_part(x)\n",
    "        return x_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723424e0",
   "metadata": {},
   "source": [
    "**VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35f11392",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config, self.encoder.conv_to_flatten_shape)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, z_mean, z_log_var, z\n",
    "\n",
    "    def loss_function(self, x_original: torch.Tensor, x_reconstructed: torch.Tensor, \n",
    "                      z_mean: torch.Tensor, z_log_var: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        bce_loss = nn.functional.binary_cross_entropy(x_reconstructed, x_original, reduction='none')\n",
    "        reconstruction_loss = torch.mean(torch.sum(bce_loss, dim=(1, 2, 3)))\n",
    "        kl_loss = torch.mean(-0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return {\"total_loss\": total_loss, \"reconstruction_loss\": reconstruction_loss, \"kl_loss\": kl_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749da0e",
   "metadata": {},
   "source": [
    "**TRAINING LOOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c24d5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(config: TrainingConfig, vae: VAE, train_loader: DataLoader):\n",
    "    device = torch.device(config.device)\n",
    "    vae.to(device)\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    log_path = os.path.join(config.current_log_dir, \"training_log.csv\")\n",
    "    if os.path.exists(log_path) and config.load_pretrained_if_exists:\n",
    "        log_df = pd.read_csv(log_path)\n",
    "        if not log_df.empty:\n",
    "            start_epoch = log_df[\"epoch\"].iloc[-1] + 1\n",
    "            best_loss = log_df[config.early_stopping_monitor].min()\n",
    "    else:\n",
    "        log_df = pd.DataFrame(columns=[\"epoch\", \"total_loss\", \"reconstruction_loss\", \"kl_loss\"])\n",
    "\n",
    "    if config.load_pretrained_if_exists:\n",
    "        checkpoint_file = os.path.join(config.current_checkpoint_dir, \"vae_best.safetensors\")\n",
    "        if os.path.exists(checkpoint_file):\n",
    "            print(f\"Caricamento modello da {checkpoint_file}\")\n",
    "            load_file(vae, checkpoint_file, device=str(device))\n",
    "            print(f\"Modello caricato. Riprendendo da epoch {start_epoch}.\")\n",
    "        else:\n",
    "            print(f\"Nessun checkpoint .safetensors trovato. Addestramento da zero.\")\n",
    "\n",
    "    for epoch in range(start_epoch, config.epochs):\n",
    "        vae.train()\n",
    "        epoch_losses = {\"total_loss\": 0, \"reconstruction_loss\": 0, \"kl_loss\": 0}\n",
    "        \n",
    "        for data, _ in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_reconstructed, z_mean, z_log_var, _ = vae(data)\n",
    "            losses = vae.loss_function(data, x_reconstructed, z_mean, z_log_var)\n",
    "            losses[\"total_loss\"].backward()\n",
    "            optimizer.step()\n",
    "            for k, v in losses.items():\n",
    "                epoch_losses[k] += v.item()\n",
    "\n",
    "        avg_losses = {k: v / len(train_loader) for k, v in epoch_losses.items()}\n",
    "        print(f\"--- Epoch {epoch+1} | Avg Loss: {avg_losses['total_loss']:.4f} ---\")\n",
    "\n",
    "        new_log_row = pd.DataFrame([{\"epoch\": epoch, **avg_losses}])\n",
    "        log_df = pd.concat([log_df, new_log_row], ignore_index=True)\n",
    "        log_df.to_csv(log_path, index=False)\n",
    "\n",
    "        current_loss = avg_losses[config.early_stopping_monitor]\n",
    "        if current_loss < best_loss - config.early_stopping_min_delta:\n",
    "            best_loss = current_loss\n",
    "            epochs_no_improve = 0\n",
    "            save_file(vae.state_dict(), os.path.join(config.current_checkpoint_dir, \"vae_best.safetensors\"))\n",
    "            print(f\"Nuovo best loss: {best_loss:.4f}. Checkpoint salvato come vae_best.safetensors\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epoch > 0 and epoch % config.save_every_n_epochs == 0:\n",
    "            save_file(vae.state_dict(), os.path.join(config.current_checkpoint_dir, f\"vae_epoch_{epoch}.safetensors\"))\n",
    "            print(f\"Checkpoint salvato per l'epoca {epoch} come .safetensors\")\n",
    "\n",
    "        if epochs_no_improve >= config.early_stopping_patience:\n",
    "            print(f\"Early stopping attivato dopo {epoch+1} epoche.\")\n",
    "            break\n",
    "            \n",
    "    save_file(vae.state_dict(), os.path.join(config.current_checkpoint_dir, \"vae_final.safetensors\"))\n",
    "    print(\"Addestramento completato. Modello finale salvato come vae_final.safetensors\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbd2cc",
   "metadata": {},
   "source": [
    "**LATENT SPACE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bed94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_latent_space(config: TrainingConfig, vae: VAE, data_loader: DataLoader):\n",
    "    device = torch.device(config.device)\n",
    "    vae.to(device)\n",
    "    vae.eval()\n",
    "\n",
    "    checkpoint_path = os.path.join(config.current_checkpoint_dir, \"vae_best.safetensors\")\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        checkpoint_path = os.path.join(config.current_checkpoint_dir, \"vae_final.safetensors\")\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Caricamento modello per inferenza da {checkpoint_path}\")\n",
    "        load_file(vae, checkpoint_path, device=str(device))\n",
    "    else:\n",
    "        print(\"ATTENZIONE: Nessun modello .safetensors trovato per l'inferenza.\")\n",
    "\n",
    "    all_z_mean, all_z_log_var, all_labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            data = data.to(device)\n",
    "            z_mean, z_log_var, _ = vae.encoder(data)\n",
    "            all_z_mean.append(z_mean.cpu().numpy())\n",
    "            all_z_log_var.append(z_log_var.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    z_data_combined = np.concatenate([np.concatenate(all_z_mean), np.concatenate(all_z_log_var)], axis=1)\n",
    "    labels_np = np.concatenate(all_labels)\n",
    "\n",
    "    latent_space_dir = os.path.join(config.base_data_dir, \"latent_space_dataset_pytorch\")\n",
    "    os.makedirs(latent_space_dir, exist_ok=True)\n",
    "    \n",
    "    output_filename = os.path.join(latent_space_dir, f\"{config.current_run_name}.pkl\")\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        pickle.dump([z_data_combined, labels_np], f)\n",
    "    print(f\"Dati dello spazio latente salvati in: {output_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783503f",
   "metadata": {},
   "source": [
    "**MAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cf1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento configurazione da: config.json5\n",
      "Configurazione caricata: TrainingConfig(run_name='custom_antennas_1_2', device='cpu')\n",
      "Dati già trovati in ./data\\S1\\dataset\n",
      "Lista file per il dataset: ['./data\\\\S1\\\\dataset\\\\S1a_A.mat', './data\\\\S1\\\\dataset\\\\S1a_B.mat', './data\\\\S1\\\\dataset\\\\S1a_C.mat', './data\\\\S1\\\\dataset\\\\S1a_D.mat', './data\\\\S1\\\\dataset\\\\S1a_E.mat']\n",
      "Caricamento file MAT...\n",
      "Processato ./data\\S1\\dataset\\S1a_A.mat, 11551 finestre aggiunte.\n",
      "Processato ./data\\S1\\dataset\\S1a_B.mat, 11551 finestre aggiunte.\n",
      "Processato ./data\\S1\\dataset\\S1a_C.mat, 11551 finestre aggiunte.\n",
      "Processato ./data\\S1\\dataset\\S1a_D.mat, 11551 finestre aggiunte.\n",
      "Processato ./data\\S1\\dataset\\S1a_E.mat, 11551 finestre aggiunte.\n",
      "Dataset inizializzato. CSI shape: torch.Size([60000, 2048, 2])\n",
      "Numero totale di finestre: 57755\n",
      "Parametri totali del modello: 185942\n",
      "\n",
      "--- Inizio Addestramento ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = TrainingConfig(config_path='config.json5')\n",
    "    print(f\"Configurazione caricata: {config}\")\n",
    "\n",
    "    download_and_prepare_data(config)\n",
    "    \n",
    "    file_list = [os.path.join(config.dataset_path, f\"{config.dataset_name}a_{x}.mat\")\n",
    "                 for x in string.ascii_uppercase[:config.num_activities]]\n",
    "    print(f\"Lista file per il dataset: {file_list}\")\n",
    "\n",
    "    try:\n",
    "        csi_dataset = CsiPyTorchDataset(config, file_list)\n",
    "        if len(csi_dataset) == 0:\n",
    "            print(\"ERRORE: Dataset vuoto. Terminazione.\")\n",
    "            exit()\n",
    "        train_loader = DataLoader(csi_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Errore fatale durante la creazione del dataset/dataloader: {e}\")\n",
    "        traceback.print_exc()\n",
    "        exit()\n",
    "\n",
    "    vae_model = VAE(config)\n",
    "    print(f\"Parametri totali del modello: {sum(p.numel() for p in vae_model.parameters())}\")\n",
    "    \n",
    "    print(\"\\n--- Inizio Addestramento ---\")\n",
    "    train_vae(config, vae_model, train_loader)\n",
    "\n",
    "    print(\"\\n--- Inizio Generazione Spazio Latente ---\")\n",
    "    generate_and_save_latent_space(config, vae_model, train_loader)\n",
    "\n",
    "    print(\"\\nProcesso completato.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
