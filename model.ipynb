{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19f2734",
   "metadata": {},
   "source": [
    "<h1>Variational Autoencoder (VAE) Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34274d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wget\n",
    "import zipfile\n",
    "import json5  \n",
    "from safetensors.torch import load_file, save_file \n",
    "from typing import Tuple, List, Dict\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "\n",
    "\n",
    "from config_setup import TrainingConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ae0d5",
   "metadata": {},
   "source": [
    "<h3>Encoder </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15bcef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        layers = []\n",
    "        current_channels = config.input_channels\n",
    "        dummy_h, dummy_w = config.window_size, config.feature_dim \n",
    "        \n",
    "        for layer_cfg in config.encoder_conv_configs:\n",
    "            # Extract parameters for Conv2d, excluding 'activation'\n",
    "            conv_params = {k: v for k, v in layer_cfg.items() if k != 'activation'}\n",
    "            layers.append(nn.Conv2d(current_channels, **conv_params))\n",
    "            current_channels = layer_cfg[\"out_channels\"]\n",
    "            if \"activation\" in layer_cfg:\n",
    "                # Call the static method from the TrainingConfig class\n",
    "                layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "            \n",
    "            kh, kw = layer_cfg[\"kernel_size\"]\n",
    "            sh, sw = layer_cfg[\"stride\"]\n",
    "            ph, pw = (layer_cfg.get(\"padding\", 0),)*2 if isinstance(layer_cfg.get(\"padding\", 0), int) else layer_cfg.get(\"padding\", 0)\n",
    "            dummy_h = math.floor((dummy_h + 2 * ph - kh) / sh + 1)\n",
    "            dummy_w = math.floor((dummy_w + 2 * pw - kw) / sw + 1)\n",
    "\n",
    "        layers.append(nn.Flatten())\n",
    "        self.conv_to_flatten_shape = (current_channels, dummy_h, dummy_w)\n",
    "        flattened_size = current_channels * dummy_h * dummy_w\n",
    "        \n",
    "        current_features = flattened_size \n",
    "        for layer_cfg in config.encoder_fc_configs:\n",
    "            layers.append(nn.Linear(current_features, layer_cfg[\"out_features\"]))\n",
    "            current_features = layer_cfg[\"out_features\"]\n",
    "            if \"activation\" in layer_cfg:\n",
    "                layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.fc_z_mean = nn.Linear(current_features, config.latent_dim)\n",
    "        self.fc_z_log_var = nn.Linear(current_features, config.latent_dim)\n",
    "    \n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x_encoded = self.model(x)\n",
    "        z_mean = self.fc_z_mean(x_encoded)\n",
    "        z_log_var = self.fc_z_log_var(x_encoded)\n",
    "        std = torch.exp(0.5 * z_log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = z_mean + eps * std\n",
    "        return z_mean, z_log_var, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eaa816",
   "metadata": {},
   "source": [
    "<h3> Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2b52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config: TrainingConfig, encoder_conv_output_shape: Tuple[int, int, int]):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.encoder_conv_output_shape = encoder_conv_output_shape\n",
    "        layers = []\n",
    "        decoder_start_features = np.prod(encoder_conv_output_shape)\n",
    "        \n",
    "        current_features = config.latent_dim\n",
    "        if config.decoder_fc_configs:\n",
    "            for layer_cfg in config.decoder_fc_configs:\n",
    "                layers.append(nn.Linear(current_features, layer_cfg[\"out_features\"]))\n",
    "                current_features = layer_cfg[\"out_features\"]\n",
    "                if \"activation\" in layer_cfg:\n",
    "                    layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "            layers.append(nn.Linear(current_features, decoder_start_features))\n",
    "        else:\n",
    "            layers.append(nn.Linear(config.latent_dim, decoder_start_features))\n",
    "\n",
    "        if config.encoder_fc_configs:\n",
    "             layers.append(TrainingConfig.get_activation(config.encoder_fc_configs[-1]['activation']))\n",
    "\n",
    "        self.fc_part = nn.Sequential(*layers)\n",
    "        \n",
    "        conv_transpose_layers = []\n",
    "        current_channels = self.encoder_conv_output_shape[0]\n",
    "        for i, layer_cfg in enumerate(config.decoder_conv_transpose_configs):\n",
    "            conv_params = {k: v for k, v in layer_cfg.items() if k != 'activation'}\n",
    "            conv_transpose_layers.append(nn.ConvTranspose2d(current_channels, **conv_params))\n",
    "            current_channels = layer_cfg[\"out_channels\"]\n",
    "            if \"activation\" in layer_cfg:\n",
    "                 conv_transpose_layers.append(TrainingConfig.get_activation(layer_cfg[\"activation\"]))\n",
    "\n",
    "        self.conv_transpose_part = nn.Sequential(*conv_transpose_layers)\n",
    "        \n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc_part(z)\n",
    "        x = x.view(-1, *self.encoder_conv_output_shape)\n",
    "        x_reconstructed = self.conv_transpose_part(x)\n",
    "        return x_reconstructed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79919ab",
   "metadata": {},
   "source": [
    "<h3> VAE </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc1f957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config, self.encoder.conv_to_flatten_shape)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, z_mean, z_log_var, z\n",
    "\n",
    "    def loss_function(self, x_original: torch.Tensor, x_reconstructed: torch.Tensor, \n",
    "                      z_mean: torch.Tensor, z_log_var: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        bce_loss = nn.functional.binary_cross_entropy(x_reconstructed, x_original, reduction='none')\n",
    "        reconstruction_loss = torch.mean(torch.sum(bce_loss, dim=(1, 2, 3)))\n",
    "        kl_loss = torch.mean(-0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return {\"total_loss\": total_loss, \"reconstruction_loss\": reconstruction_loss, \"kl_loss\": kl_loss}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
