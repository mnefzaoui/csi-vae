{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE training and processing\n",
    "\n",
    "Sample code to train a new VAE and run the CSI processing."
   ]
  },
 {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95cc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wget\n",
    "import zipfile\n",
    "import json5  \n",
    "from safetensors.torch import load_file, save_file \n",
    "from typing import Tuple, List, Dict\n",
    "import pandas as pd\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "from config_setup import TrainingConfig\n",
    "from data_utils import download_and_prepare_data, CsiPyTorchDataset\n",
    "from model import VAE\n",
    "from training import train_vae, generate_and_save_latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dcc5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from: config.json5\n",
      "Configuration loaded: TrainingConfig(run_name='custom_antennas_0_1', device='cpu')\n",
      "Data already found in ./data\\S1\\dataset\n",
      "Building file list for scenario S1...\n",
      "Receivers: ['a'], Activities: ['A', 'B', 'C']\n",
      "Generated file list for the dataset (3 files): ['./data\\\\S1\\\\dataset\\\\S1a_A.mat', './data\\\\S1\\\\dataset\\\\S1a_B.mat', './data\\\\S1\\\\dataset\\\\S1a_C.mat']\n",
      "Loading MAT files...\n",
      "Processed  ./data\\S1\\dataset\\S1a_A.mat, 11551 windows added.\n",
      "Processed  ./data\\S1\\dataset\\S1a_B.mat, 11551 windows added.\n",
      "Processed  ./data\\S1\\dataset\\S1a_C.mat, 11551 windows added.\n",
      "Dataset initialized. CSI shape: torch.Size([36000, 2048, 2])\n",
      "Total number of windows: 34653\n",
      "Total model parameters: 185942\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = TrainingConfig(config_path='config.json5')\n",
    "    print(f\"Configuration loaded: {config}\")\n",
    "\n",
    "    download_and_prepare_data(config)\n",
    "    \n",
    "    #file_list = [os.path.join(config.dataset_path, f\"{config.dataset_name}a_{x}.mat\")\n",
    "    #             for x in string.ascii_uppercase[:config.num_activities]]\n",
    "    #print(f\"File list for the dataset: {file_list}\")\n",
    "\n",
    "\n",
    "     # --- Dynamic File List Construction Logic ---\n",
    "    file_list = []\n",
    "    # Ensures that configuration parameters are always lists\n",
    "    receivers = config.receivers if isinstance(config.receivers, list) else [config.receivers]\n",
    "    activities = config.activities if isinstance(config.activities, list) else [config.activities]\n",
    "\n",
    "    print(f\"Building file list for scenario {config.dataset_name}...\")\n",
    "    print(f\"Receivers: {receivers}, Activities: {activities}\")\n",
    "\n",
    "    for receiver_id in receivers:\n",
    "        for activity_id in activities:\n",
    "            # Builds the file name according to the convention: S{x}{y}_{Z}.mat\n",
    "            \n",
    "            file_name = f\"{config.dataset_name}{receiver_id}_{activity_id}.mat\"\n",
    "            full_path = os.path.join(config.dataset_path, file_name)\n",
    "            \n",
    "            if os.path.exists(full_path):\n",
    "                file_list.append(full_path)\n",
    "            else:\n",
    "                print(f\"Warning: File not found and will be skipped: {full_path}\")\n",
    "\n",
    "    if not file_list:\n",
    "        print(\"ERROR: No files found for the specified configuration. Please check config.json5 and the data directory.\")\n",
    "        exit()\n",
    "        \n",
    "    print(f\"Generated file list for the dataset ({len(file_list)} files): {file_list}\")\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        csi_dataset = CsiPyTorchDataset(config, file_list)\n",
    "        if len(csi_dataset) == 0:\n",
    "            print(\"ERROR: Dataset is empty. Terminating.\")\n",
    "            exit()\n",
    "        train_loader = DataLoader(csi_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error during dataset/dataloader creation: {e}\")\n",
    "        traceback.print_exc()\n",
    "        exit()\n",
    "\n",
    "    vae_model = VAE(config)\n",
    "    print(f\"Total model parameters: {sum(p.numel() for p in vae_model.parameters())}\")\n",
    "    \n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "    train_vae(config, vae_model, train_loader)\n",
    "\n",
    "    print(\"\\n--- Starting Latent Space Generation ---\")\n",
    "    generate_and_save_latent_space(config, vae_model, train_loader)\n",
    "\n",
    "    print(\"\\nProcess completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
